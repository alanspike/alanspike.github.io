<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
    <meta name=viewport content=â€œwidth=800â€>
    <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
    <style type="text/css">
        /* Color scheme stolen from Sergey Karayev */
        a {
            color: #1772d0;
            text-decoration: none;
        }

        a:focus,
        a:hover {
            color: #f09228;
            text-decoration: none;
        }

        body,
        td,
        th,
        tr,
        p,
        a {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 14px
        }

        strong {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 14px;
        }

        heading {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 22px;
        }

        headingsmall {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 18px;
        }

        papertitle {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 14px;
            font-weight: 700
        }

        name {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 32px;
        }

        .one {
            width: 160px;
            height: 160px;
            position: relative;
        }

        .two {
            width: 160px;
            height: 160px;
            position: absolute;
            transition: opacity .2s ease-in-out;
            -moz-transition: opacity .2s ease-in-out;
            -webkit-transition: opacity .2s ease-in-out;
        }

        .fade {
            transition: opacity .2s ease-in-out;
            -moz-transition: opacity .2s ease-in-out;
            -webkit-transition: opacity .2s ease-in-out;
        }

        span.highlight {
            background-color: #ffffd0;
        }
    </style>
    <title>Jian Ren Rutgers</title>
    <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
    <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet'
        type='text/css'>
</head>

<body>
    <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
        <tr>
            <td>
                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <tr>
                        <td width="67%" valign="middle">
                            <p align="center">
                                <name>Jian Ren</name>
                            </p>
                            <p>
                                I am a Research Scientist working in the <a
                                    href="https://research.snap.com/team/category/creative-vision/">
                                    Creative Vision group</a> at Snap Inc. Before joining Snap Inc., I worked as a
                                Research Intern at Adobe, Snap Inc., and Bytedance Research.
                            </p>
                            <p>

                                I got a Ph.D. in Computer Engineering at <a href="https://www.rutgers.edu/">Rutgers
                                    University</a>
                                under the supervision of <a
                                    href="https://gemini.cinj.rutgers.edu/rutgers-people/david-j-foran-phd/">Professor
                                    David J. Foran</a>
                                and <a href="http://manishparashar.org/">Professor Manish Parashar</a>, and a B.S.
                                degree
                                in Electrical Engineering from <a href="http://en.ustc.edu.cn/">University of Science
                                    and Technology of China</a>. I'm interested
                                in computer
                                vision, machine learning, high-performance computing, deep learning, and generative
                                adversarial
                                networks.
                            </p>
                            <!-- <p>
                                Before joining Rutgers, I obtained B.S. degree in Electrical Engineering from <a
                                    href="http://en.ustc.edu.cn/">University of Science and Technology of China</a>. I
                                also spent one
                                semester at <a href="http://nthu-en.web.nthu.edu.tw/bin/home.php/">National Tsing Hua
                                    University</a>.
                            </p> -->


                            <p align=center>
                                <a href="mailto:renjianustc@gmail.com">Email</a> &nbsp/&nbsp
                                <a href="data/CV.pdf">CV</a> &nbsp/&nbsp
                                <a href="https://www.linkedin.com/in/renjian0905//"> LinkedIn </a>
                            </p>
                        </td>
                        <td width="10%">
                            <img src="images/head.png">
                        </td>
                    </tr>
                </table>

                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

                    <font color="blue"><strong>[Internship/Collaboration Opportunities]</strong></font>.
                    We are always looking for self-motivated interns throughout the year. Please feel free to drop me an
                    email if you are interested in working on computer vision, machine learning, and deep learning.

                    <!-- <tr>
                        <td>
                            <heading>Industry Experience</heading>
                            <ul></ul>
                            <headingsmall><a href="http://ailab.bytedance.com/">US AI Lab, Bytedance Inc.</a>
                            </headingsmall>
                            <ul>
                                <p>
                                    <li> Intern, 01/2019 -- 04/2019 </li>
                                    <li> Worked on human motion retargeting. </li>
                                </p>
                            </ul>


                            <headingsmall><a href="https://www.snap.com/en-US/">Research Lab, Snap Inc.</a>
                            </headingsmall>
                            <ul>
                                <p>
                                    <li> Intern, 06/2017 -- 12/2017 </li>
                                    <li> Worked on adversarial learning for high-level tasks on large-scale datasets.
                                    </li>
                                    <li> Worked on evolution algorithm for automatically searching neural network
                                        architectures. </li>
                                </p>
                            </ul>

                            <headingsmall><a href="https://research.adobe.com/">Imagination Lab, Adobe Systems, Inc.</a>
                            </headingsmall>
                            <ul>
                                <p>
                                    <li> Intern, 05/2016 -- 05/2017 </li>
                                    <li> Worked on image aesthetics for the customized recommendation. Shipped the
                                        aesthetics filter in <a href="https://stock.adobe.com/">Adobe Stock</a>. </li>
                                    <li> Worked on album curation. Shipped the <a
                                            href="https://www.adobe.com/products/photoshop-premiere-elements/features.html#auto-curate">Auto
                                            Curate</a> in Elements Organizer 2018.</li>
                                    <li> Worked on the best frame selection from short videos. Shipped the <a
                                            href="https://www.adobe.com/products/photoshop-premiere-elements/features.html#candid-moments">Candid
                                            Moments</a> in Premiere Elements 2018.</li>
                                </p>
                            </ul>
                        </td>
                    </tr> -->
                </table>




                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <tr>
                        <td>
                            <heading>Publications</heading>


                            <!-- &nbsp; &nbsp; <b>Journal:</b> -->
                            <ul>
                                <li>
                                    <i> Teachers Do More Than Teach: Compressing Image-to-Image Models.
                                        Qing Jin, Jian Ren, Oliver Woodford, Jiazhuo Wang, Geng Yuan, Yanzhi Wang,
                                        and Sergey Tulyakov.
                                        CVPR, 2021.
                                </li>

                            </ul>
                            <ul>
                                <li>
                                    <i> Flow Guided Transformable Bottleneck Networks for Motion Retargeting.</i>
                                    Jian Ren, Menglei Chai, Oliver Woodford, Kyle Olszewski, and Sergey Tulyakov.
                                    CVPR, 2021.
                                </li>

                            </ul>
                            <ul>
                                <li>
                                    <i> Motion Representations for Articulated Animation.</i>
                                    Aliaksandr Siarohin, Oliver Woodford, Jian Ren, Menglei Chai, and
                                    Sergey Tulyakov.
                                    CVPR, 2021.
                                </li>

                            </ul>
                            <ul>
                                <li>
                                    <i> A Good Image Generator Is What You Need for High-Resolution Video Synthesis.</i>
                                    Yu Tian, Jian Ren, Menglei Chai, Kyle Olszewski, Xi Peng, Dimitris N. Metaxas,
                                    Sergey Tulyakov.
                                    ICLR, 2021. <font color="red">Spotlight</font>.
                                </li>
                                [<a href="https://openreview.net/forum?id=6puCSjH3hwA">OpenReview</a>]
                                <!-- [<a href="https://arxiv.org/abs/2004.13297">arXiv</a>] -->
                            </ul>

                            <ul>
                                <li>
                                    <i> SMIL: Multimodal learning with severely missing modality.</i>
                                    Mengmeng Ma, Jian Ren, Long Zhao, Sergey Tulyakov, Cathy Wu, and Xi Peng.
                                    AAAI, 2021.
                                </li>
                                <!-- [<a href="https://arxiv.org/abs/2004.13297">arXiv</a>] -->
                            </ul>
                            <ul>
                                <li>
                                    <i>Neural Hair Rendering</i>.
                                    Menglei Chai, Jian Ren, and Sergey Tulyakov.
                                    ECCV, 2020.
                                </li>
                                [<a href="https://arxiv.org/abs/2004.13297">arXiv</a>]
                            </ul>

                            <ul>
                                <li>
                                    <i>Human Motion Transfer from Poses in the Wild</i>.
                                    Jian Ren, Menglei Chai, Sergey Tulyakov, Chen Fang, Xiaohui Shen, and Jianchao Yang.
                                    ECCV Workshop, 2020.
                                </li>
                                [<a href="https://arxiv.org/abs/2004.03142">arXiv</a>]
                            </ul>
                            <ul>
                                <li>
                                    <i>Best Frame Selection in a Short Video</i>.
                                    Jian Ren, Xiaohui Shen, Zhe Lin, and Radomir Mech.
                                    WACV, 2020.
                                </li>
                                [<a
                                    href="https://openaccess.thecvf.com/content_WACV_2020/papers/Ren_Best_Frame_Selection_in_a_Short_Video_WACV_2020_paper.pdf">Paper</a>]

                            </ul>
                            <ul>
                                <li>
                                    <i>EIGEN:
                                        Ecologically-Inspired GENetic Approach for Neural Network Structure Searching
                                        from Scratch</i>.
                                    Jian Ren, Zhe Li, Jianchao Yang, Ning Xu, Tianbao Yang, and David J. Foran.
                                    CVPR, 2019.
                                </li>
                                [<a href="https://arxiv.org/abs/1806.01940">arXiv</a>]
                            </ul>

                            <ul>
                                <li>
                                    <i>Unsupervised Domain Adaptation for Classification of Histopathology Whole-Slide
                                        Images</i>.
                                    Jian Ren, Ilker Hacihaliloglu, Eric A. Singer, David J. Foran, and Xin Qi.
                                    Frontiers in
                                    Bioengineering and Biotechnology, 2019.
                                </li>
                                [<a
                                    href="https://www.frontiersin.org/articles/10.3389/fbioe.2019.00102/abstract">Paper</a>]
                            </ul>

                            <ul>
                                <li>
                                    <i>Statistical Analysis
                                        on Survival Models using Feature Quantification on Prostate Cancer
                                        Histopathology Images</i>.
                                    Jian Ren, Eric A. Singer, Evita T. Sadimin, David J. Foran, and Xin Qi.
                                    Journal of Pathology Informatics, 2019.
                                </li>
                                [<a href="https://www.jpathinformatics.org/article.asp?issn=2153-3539;year=2019;volume=10;issue=1;spage=30;epage=30;aulast=Ren
                                    ">Paper</a>]
                            </ul>
                            <ul>
                                <li>
                                    <i>Recurrence Analysis on Prostate Cancer Patients with Gleason Score 7
                                        using Integrated
                                        Histopathology Whole-Slide Images and Genomic Data through Deep Neural
                                        Networks</i>.
                                    Jian Ren, Kubra Karagoz, Michael L. Gatza, Eric A. Singer, Evita T. Sadimin,
                                    David J. Foran,
                                    and Xin Qi. Journal of
                                    Medical Imaging, 2018.
                                </li>
                                [<a
                                    href="https://www.spiedigitallibrary.org/journals/journal-of-medical-imaging/volume-5/issue-4/047501/Recurrence-analysis-on-prostate-cancer-patients-with-Gleason-score-7/10.1117/1.JMI.5.4.047501.full?SSO=1">Paper</a>]
                            </ul>


                            <!-- &nbsp; &nbsp; <b>Conference:</b> -->

                            <ul>
                                <li>
                                    <i>Adversarial
                                        Domain Adaptation for Classification of Prostate Histopathology Whole-Slide
                                        Images</i>.
                                    Jian Ren, Ilker Hacihaliloglu, Eric A. Singer, David J. Foran, and Xin Qi.
                                    MICCAI,
                                    2018. <font color="red">Oral</font>.
                                </li>
                                [<a href="https://arxiv.org/abs/1806.01357">arXiv</a>]
                            </ul>

                            <ul>
                                <li>
                                    <i>Differentiation among
                                        Prostate Cancer Patients with Gleason Score of 7 using Histopathology Image and
                                        Genomic Data</i>.
                                    Jian Ren, Kubra Karagoz, Michael L. Gatza, David J. Foran, and Xin Qi.

                                    SPIE Medical Imaging, 2018. <font color="red">Oral</font>.
                                </li>
                                [<a
                                    href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10579/1057904/Differentiation-among-prostate-cancer-patients-with-Gleason-score-of-7/10.1117/12.2293193.short">Paper</a>]
                            </ul>
                            <ul>
                                <li>
                                    <i>Factorized
                                        Adversarial Networks for
                                        Unsupervised Domain Adaptation</i>.
                                    Jian Ren, Jianchao Yang, Ning Xu, and David J. Foran. 2018.
                                </li>
                                [<a href="https://arxiv.org/abs/1806.01376">arXiv</a>]
                            </ul>
                            <ul>
                                <li>
                                    <i>Personalized Image
                                        Aesthetics</i>.
                                    Jian Ren, Xiaohui Shen, Zhe Lin, Radomir Mech, and David J. Foran.
                                    ICCV, 2017.
                                </li>
                                [<a
                                    href="http://openaccess.thecvf.com/content_iccv_2017/html/Ren_Personalized_Image_Aesthetics_ICCV_2017_paper.html">Paper</a>]
                                [<a href="https://github.com/alanspike/personalizedImageAesthetics">code</a>]
                            </ul>

                            <!-- <ul>
                                <li>
                                    <i>Computer Aided
                                        Analysis of Prostate
                                        Histopathology Images to Support a Refined Gleason Grading System</i>.
                                    Jian Ren, Evita T. Sadimin, David J. Foran, and Xin Qi. SPIE
                                    Medical Imaging, 2017.
                                </li>
                                [<a
                                    href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10133/101331V/Computer-aided-analysis-of-prostate-histopathology-images-to-support-a/10.1117/12.2253887.full">Paper</a>]
                            </ul>

                            <ul>
                                <li>
                                    <i>Computer Aided Analysis of Prostate Histopathology Images Gleason Grading
                                        especially for Gleason
                                        Score 7</i>.
                                    Jian Ren, Evita T. Sadimin, Daihou Wang, Jonathan I. Epstein, David J. Foran,
                                    and Xin Qi.
                                    EMBS, 2015.
                                </li>
                                [<a href="https://www.ncbi.nlm.nih.gov/pubmed/26736926">Paper</a>]
                            </ul>
 -->






                        </td>
                    </tr>
                </table>



                <table cellspacing="0" cellpadding="20" width="100%" border="0" align="center">
                    <tbody>
                        <tr>
                            <td>
                                <br>
                                <p align="right">
                                    <font size="2">
                                        <a href="https://people.eecs.berkeley.edu/%7Ebarron/">Webpage Credits</a>.
                                    </font>
                                </p>
                            </td>
                        </tr>
                    </tbody>
                </table>

                <script type="text/javascript">
                    var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
                    document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));

                </script>
                <script type="text/javascript">
                    try {
                        var pageTracker = _gat._getTracker("UA-7580334-1");
                        pageTracker._trackPageview();
                    } catch (err) { }
                </script>
            </td>
        </tr>
    </table>
</body>

</html>